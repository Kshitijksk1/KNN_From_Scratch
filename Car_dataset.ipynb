{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************THE OUTPUT OF EUCLIDIAN******************\n",
      "Result of the Car Dataset: [92.44186046511628, 92.44186046511628, 93.6046511627907, 92.44186046511628, 93.6046511627907, 95.34883720930233, 87.79069767441861, 94.18604651162791, 93.6046511627907, 94.76744186046511]\n",
      "Mean Accuracy of the Car program: 93.023%\n",
      "*******************THE OUTPUT OF HAMMING******************\n",
      "Result of the Car Dataset using Hamming Distance: [93.6046511627907, 87.79069767441861, 88.95348837209302, 87.20930232558139, 94.18604651162791, 89.53488372093024, 91.27906976744185, 88.37209302325581, 88.37209302325581, 87.79069767441861]\n",
      "Mean Accuracy of the Car program using Hamming Distance: 89.709%\n",
      "*******************THE OUTPUT OF MANHATTAN******************\n",
      "Result of the Car Dataset using manhattan Distance: [96.51162790697676, 91.86046511627907, 93.6046511627907, 93.02325581395348, 90.11627906976744, 94.76744186046511, 96.51162790697676, 94.18604651162791, 94.18604651162791, 95.34883720930233]\n",
      "Mean Accuracy of the Car program using manhattan Distance: 94.012%\n",
      "*******************THE OUTPUT OF MINKOWSKI******************\n",
      "Result of the Car Dataset using minkowski Distance: [94.76744186046511, 95.34883720930233, 96.51162790697676, 95.34883720930233, 93.6046511627907, 93.6046511627907, 95.34883720930233, 93.02325581395348, 95.93023255813954, 90.69767441860465]\n",
      "Mean Accuracy of the Car program using minkowski Distance: 94.419%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from math import sqrt\n",
    "from math import exp\n",
    "from csv import reader\n",
    "read_file = pd.read_csv (r'car.data')\n",
    "read_file.to_csv (r'car.csv', index=None)\n",
    "dataset_demo = pd.read_csv('car.csv')\n",
    "\n",
    "def load_csv(file_name):\n",
    "\tfile_value = open(file_name, \"rt\")\n",
    "\tlines_value = reader(file_value)\n",
    "\tdataset_details = list(lines_value)\n",
    "\treturn dataset_details\n",
    "\n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset_value, column_value):\n",
    "\tfor row_value in dataset_value:\n",
    "\t\trow_value[column_value] = float(row_value[column_value])\n",
    "        \n",
    "# Conversions of the string value  column to integer format.\n",
    "def str_column_to_int(dataset, column_value):\n",
    "\tclass_values = [row[column_value] for row in dataset] #processing through each and every value in the  class columns\n",
    "\tunique = set(class_values) # while set does not contains duplicate values\n",
    "\tlookup = dict() \n",
    "\tfor i, value in enumerate(unique):\n",
    "\t\tlookup[value] = i #conversions class values to integers value\n",
    "\tfor row in dataset:\n",
    "\t\trow[column_value] = lookup[row[column_value]] #assigning integer values to class columns\n",
    "\treturn lookup\n",
    "\n",
    "# Load the value of the dataset in the list form\n",
    "filename_value = 'car.data'\n",
    "dataset = load_csv(filename_value)\n",
    "\n",
    "# convert class column to int\n",
    "for i in range(len(dataset[0])):\n",
    "    lookup = str_column_to_int(dataset, i)\n",
    "# convert the content of the columns which is in string form to float\n",
    "for i in range(len(dataset[0])):\n",
    "    str_column_to_float(dataset, i)\n",
    "    \n",
    "# Find the min and max values for each column\n",
    "def dataset_minmax(dataset):\n",
    "\tminmax = list()\n",
    "\tfor i in range(len(dataset[0])):\n",
    "\t\tcol_values = [row[i] for row in dataset]\n",
    "\t\tvalue_min = min(col_values)\n",
    "\t\tvalue_max = max(col_values)\n",
    "\t\tminmax.append([value_min, value_max])\n",
    "\treturn minmax\n",
    "\n",
    "# Rescale dataset columns to the range 0-1\n",
    "def normalize_dataset(dataset, minmax):\n",
    "\tfor row in dataset:\n",
    "\t\tfor i in range(len(row)):\n",
    "\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_val(dataset, n_folds):\n",
    "\tdataset_split = list()\n",
    "\tdataset_copy = list(dataset)\n",
    "\tfold_size = int(len(dataset) / n_folds)\n",
    "\tfor _ in range(n_folds):\n",
    "\t\tfold = list()\n",
    "\t\twhile len(fold) < fold_size:\n",
    "\t\t\tindex = randrange(len(dataset_copy))\n",
    "\t\t\tfold.append(dataset_copy.pop(index))\n",
    "\t\tdataset_split.append(fold)\n",
    "\treturn dataset_split\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "\tcorrect = 0\n",
    "\tfor i in range(len(actual)):\n",
    "\t\tif actual[i] == predicted[i]:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn correct / float(len(actual)) * 100.0\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate(data, alg, n_folds, *args):\n",
    "\tfolds = cross_val(data, n_folds)\n",
    "\tscores = list()\n",
    "\tfor fold in folds:\n",
    "\t\ttrain_set = list(folds)\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "\t\ttest_set = list()\n",
    "\t\tfor row in fold:\n",
    "\t\t\trow_copy = list(row)\n",
    "\t\t\ttest_set.append(row_copy)\n",
    "\t\t\trow_copy[-1] = None\n",
    "\t\tpredicted = alg(train_set, test_set, *args)\n",
    "\t\tactual = [row[-1] for row in fold]\n",
    "\t\taccuracy = accuracy_metric(actual, predicted)\n",
    "\t\tscores.append(accuracy)\n",
    "\treturn scores\n",
    "\n",
    "# Calculate the Euclidean distance between two vectors\n",
    "def euclidean_distance(row1, row2):\n",
    "\tdistance = 0.0\n",
    "\tfor i in range(len(row1)-1):\n",
    "\t\tdistance += (row1[i] - row2[i])**2\n",
    "\treturn sqrt(distance)\n",
    "\n",
    "# Locate the most similar neighbors using Euclidean Distance\n",
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "\tdistances = list()\n",
    "\tfor train_row in train:\n",
    "\t\tdist = euclidean_distance(test_row, train_row)\n",
    "\t\tdistances.append((train_row, dist))\n",
    "\tdistances.sort(key=lambda tup: tup[1])\n",
    "\tneighbors = list()\n",
    "\tfor i in range(num_neighbors):\n",
    "\t\tneighbors.append(distances[i][0])\n",
    "\treturn neighbors\n",
    "\n",
    "# Make a prediction with neighbors\n",
    "def predict_classification(train, test_row, num_neighbors):\n",
    "\tneighbors = get_neighbors(train, test_row, num_neighbors)\n",
    "\toutput_values = [row[-1] for row in neighbors]\n",
    "\tprediction = max(set(output_values), key=output_values.count)\n",
    "\treturn prediction\n",
    "\n",
    "# kNN Algorithm\n",
    "def knn(train, test, num_neighbors):\n",
    "\tpredictions = list()\n",
    "\tfor row in test:\n",
    "\t\toutput = predict_classification(train, row, num_neighbors)\n",
    "\t\tpredictions.append(output)\n",
    "\treturn(predictions)\n",
    "\n",
    "# Calculate the Hamming distance between two vectors\n",
    "def hamming_distance(row1, row2):\n",
    "\tdist_counter = 0.0\n",
    "\tfor n in range(len(row1)):\n",
    "\t\tif row1[n] != row2[n]:\n",
    "\t\t\tdist_counter += 1\n",
    "\treturn dist_counter\n",
    "\n",
    "# Locate the most similar neighbors using Hamming distance\n",
    "def get_neighbors_hamming(train, test_row, num_neighbors):\n",
    "\tdistances = list()\n",
    "\tfor train_row in train:\n",
    "\t\tdist = hamming_distance(test_row, train_row)\n",
    "\t\tdistances.append((train_row, dist))\n",
    "\tdistances.sort(key=lambda tup: tup[1])\n",
    "\tneighbors = list()\n",
    "\tfor i in range(num_neighbors):\n",
    "\t\tneighbors.append(distances[i][0])\n",
    "\treturn neighbors\n",
    "\n",
    "def predict_classification_hamming(train, test_row, num_neighbors):\n",
    "\tneighbors = get_neighbors_hamming(train, test_row, num_neighbors)\n",
    "\toutput_values = [row[-1] for row in neighbors]\n",
    "\tprediction = max(set(output_values), key=output_values.count)\n",
    "\treturn prediction\n",
    "\n",
    "def knn_hamming(train, test, num_neighbors):\n",
    "\tpredictions = list()\n",
    "\tfor row in test:\n",
    "\t\toutput = predict_classification_hamming(train, row, num_neighbors)\n",
    "\t\tpredictions.append(output)\n",
    "\treturn(predictions)\n",
    "\n",
    "def manhattan_distance(row1, row2):\n",
    "\tdistance = 0.0\n",
    "\tfor i in range(len(row1)-1):\n",
    "\t\tdistance += abs(row1[i] - row2[i])\n",
    "\treturn (distance)\n",
    "\n",
    "# Locate the most similar neighbors using Hamming distance\n",
    "def get_neighbors_manhattan(train, test_row, num_neighbors):\n",
    "\tdistances = list()\n",
    "\tfor train_row in train:\n",
    "\t\tdist = manhattan_distance(test_row, train_row)\n",
    "\t\tdistances.append((train_row, dist))\n",
    "\tdistances.sort(key=lambda tup: tup[1])\n",
    "\tneighbors = list()\n",
    "\tfor i in range(num_neighbors):\n",
    "\t\tneighbors.append(distances[i][0])\n",
    "\treturn neighbors\n",
    "\n",
    "def predict_classification_manhattan(train, test_row, num_neighbors):\n",
    "\tneighbors = get_neighbors_manhattan(train, test_row, num_neighbors)\n",
    "\toutput_values = [row[-1] for row in neighbors]\n",
    "\tprediction = max(set(output_values), key=output_values.count)\n",
    "\treturn prediction\n",
    "\n",
    "def knn_manhattan(train, test, num_neighbors):\n",
    "\tpredictions = list()\n",
    "\tfor row in test:\n",
    "\t\toutput = predict_classification_manhattan(train, row, num_neighbors)\n",
    "\t\tpredictions.append(output)\n",
    "\treturn(predictions)\n",
    "\n",
    "def minkowski_distance(row1, row2):\n",
    "\tdistance = 0.0\n",
    "\tp = 3.0\n",
    "\tfor i in range(len(row1)-1):\n",
    "\t\tdistance += abs(row1[i] - row2[i])**p\n",
    "\treturn (distance**(1.0/p))\n",
    "\n",
    "# Locate the most similar neighbors using Hamming distance\n",
    "def get_neighbors_minkowski(train, test_row, num_neighbors):\n",
    "\tdistances = list()\n",
    "\tfor train_row in train:\n",
    "\t\tdist = minkowski_distance(test_row, train_row)\n",
    "\t\tdistances.append((train_row, dist))\n",
    "\tdistances.sort(key=lambda tup: tup[1])\n",
    "\tneighbors = list()\n",
    "\tfor i in range(num_neighbors):\n",
    "\t\tneighbors.append(distances[i][0])\n",
    "\treturn neighbors\n",
    "\n",
    "def predict_classification_minkowski(train, test_row, num_neighbors):\n",
    "\tneighbors = get_neighbors_minkowski(train, test_row, num_neighbors)\n",
    "\toutput_values = [row[-1] for row in neighbors]\n",
    "\tprediction = max(set(output_values), key=output_values.count)\n",
    "\treturn prediction\n",
    "\n",
    "def knn_minkowski(train, test, num_neighbors):\n",
    "\tpredictions = list()\n",
    "\tfor row in test:\n",
    "\t\toutput = predict_classification_minkowski(train, row, num_neighbors)\n",
    "\t\tpredictions.append(output)\n",
    "\treturn(predictions)\n",
    "\n",
    "seed(1)\n",
    "n = 10 #10-k folds cross validation\n",
    "neighbors = 5\n",
    "result = evaluate(dataset, knn, n, neighbors)\n",
    "result_hamming = evaluate(dataset, knn_hamming, n, neighbors)\n",
    "result_manhattan = evaluate(dataset, knn_manhattan, n, neighbors)\n",
    "result_minkowski = evaluate(dataset, knn_minkowski, n, neighbors)\n",
    "print(\"*******************THE OUTPUT OF EUCLIDIAN******************\")\n",
    "print('Result of the Car Dataset: %s' % result)\n",
    "print('Mean Accuracy of the Car program: %.3f%%' % (sum(result)/float(len(result))))\n",
    "print(\"*******************THE OUTPUT OF HAMMING******************\")\n",
    "print('Result of the Car Dataset using Hamming Distance: %s' %result_hamming)\n",
    "print('Mean Accuracy of the Car program using Hamming Distance: %.3f%%' % (sum(result_hamming)/float(len(result_hamming))))\n",
    "print(\"*******************THE OUTPUT OF MANHATTAN******************\")\n",
    "print('Result of the Car Dataset using manhattan Distance: %s' % result_manhattan)\n",
    "print('Mean Accuracy of the Car program using manhattan Distance: %.3f%%' % (sum(result_manhattan)/float(len(result_manhattan))))\n",
    "print(\"*******************THE OUTPUT OF MINKOWSKI******************\")\n",
    "print('Result of the Car Dataset using minkowski Distance: %s' % result_minkowski)\n",
    "print('Mean Accuracy of the Car program using minkowski Distance: %.3f%%' % (sum(result_minkowski)/float(len(result_minkowski))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
